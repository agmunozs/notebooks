{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather station data limit detection\n",
    "\n",
    "This document is meant to illustrate QA method applied to our first version of public weather observation, https://data.planetos.com/datasets/noaa_synop2\n",
    "\n",
    "In the first iteration we apply a simple QA, based on 15 year data history and statistical distribution analysis. This way we can filter out a portion of clearly bad values, but a large number of suspicious values are not discovered by tis method. \n",
    "\n",
    "For statistical distribution, we take a simple approach, find the 05, 95 quantiles for each station by month, find their difference and use the difference + certain multiplier above the 95 and below the 05 quantiles, as boundaries for accepting values. This way we get very few or no false positives for variables like temperature and pressure, but a significant amount of false negatives remain in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "#from API_client.python.datahub import datahub\n",
    "#from API_client.python.lib.dataset import dataset\n",
    "\n",
    "from apiclient.datahub import datahub\n",
    "from apiclient.dataset import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109a3eeb915b4a89ad659b423fbcb1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, max=10.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.84 s, sys: 216 ms, total: 4.06 s\n",
      "Wall time: 6.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_file_path = '/data/files/eneli/synop_data_history_decoded/' ## insert data file path here\n",
    "\n",
    "dtypes = {'cloud_below_station_type':str,\n",
    "          'cloud_location_type_AC':str,\n",
    "          'cloud_location_type_AS':str,\n",
    "          'cloud_location_type_CB':str,\n",
    "          'cloud_location_type_CI':str,\n",
    "          'cloud_location_type_CS':str,\n",
    "          'cloud_location_type_CU':str,\n",
    "          'cloud_location_type_ST':str,\n",
    "          'cloud_location_type_SC':str,\n",
    "          'cloud_type_high_compass_dir':str,\n",
    "          'cloud_type_low_compass_dir':str,\n",
    "          'cloud_type_middle_compass_dir':str,\n",
    "          'hoar_frost':str,\n",
    "          'hoar_frost_phenom_descr':str,\n",
    "          'weather_present_simple':str,\n",
    "          'state_of_ground_snow':str}\n",
    "#fls = glob.glob('/data/files/eneli/synop_data_state_csv_metaf2xml/2018/5/*/*')\n",
    "\n",
    "fls = glob.glob(data_file_path + '/2017/{0}/*'.format(month))\n",
    "fin_csvs = []\n",
    "usecols = ['time','station','pressure','temperature','station_pressure']\n",
    "f = FloatProgress(min = 0, max = len(fls))\n",
    "display(f)\n",
    "for i in fls:\n",
    "    #try:\n",
    "    fin_csvs.append(pd.read_csv(i, usecols=usecols, dtype=dtypes))\n",
    "    #except:\n",
    "    #    print(\"cannot read \", i)\n",
    "    #    with open(i) as fff:\n",
    "    #        print(len(fff.readlines()))\n",
    "    f.value += 1\n",
    "fin = pd.concat(fin_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = fin['station'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_limits = {\n",
    "    \"temperature\": [-80, 65],\n",
    "    \"wind_speed\": [0, 90],\n",
    "    \"pressure\": [800,1100],\n",
    "    \"station_pressure\": [400,1100],\n",
    "    \"precipitation_1_hour_accumulation\": [0,200],\n",
    "    \"precipitation_2_hour_accumulation\": [0,250],\n",
    "    \"precipitation_3_hour_accumulation\": [0,400],\n",
    "    \"precipitation_6_hour_accumulation\": [0,400],\n",
    "    \"precipitation_9_hour_accumulation\": [0,400],\n",
    "    \"precipitation_12_hour_accumulation\": [0,400],\n",
    "    \"precipitation_15_hour_accumulation\": [0,400],\n",
    "    \"precipitation_18_hour_accumulation\": [0,400],\n",
    "    \"precipitation_24_hour_accumulation\": [0,400],\n",
    "    \"rel_humidity1\":[0,105],\n",
    "    \"rel_humidity2\":[0,105],\n",
    "    \"rel_humidity3\":[0,105],\n",
    "    \"rel_humidity4\":[0,105]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9395e372897e4bf89239631801e234c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, max=9480.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.8 s, sys: 2.41 s, total: 50.2 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## st_table -- statistics of observations by station and month\n",
    "\n",
    "\n",
    "st_table = {}\n",
    "f = FloatProgress(min = 0, max = len(stations))\n",
    "display(f)\n",
    "for st in stations:\n",
    "    stn = \"{0:05d}\".format(int(st))\n",
    "    st_table[stn] = {}\n",
    "    t_temp = fin[fin['station'] == st]\n",
    "    varis = [i for i in t_temp.columns if not i in ['time','elevation','lon','lat','station']]\n",
    "    f.value+=1\n",
    "    for v in varis:\n",
    "        v_temp = t_temp[v]\n",
    "        if v_temp.dtype == np.float64:\n",
    "            st_table[stn][v] = {}\n",
    "            if ~np.all(v_temp.isnull()):\n",
    "                st_table[stn][v] = {}\n",
    "                st_table[stn][v][v+'_max'] = v_temp.max()\n",
    "                st_table[stn][v][v+'_min'] = v_temp.min()\n",
    "                st_table[stn][v][v+'_count'] = len(v_temp)\n",
    "                st_table[stn][v][v+'_quantiles'] = list(v_temp.quantile([0.05,0.25,0.5,0.75,0.95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_limit_dictionary(stations, physical_limits, monthlist, varlist):\n",
    "    ret_dict = {}\n",
    "    for st in stations:\n",
    "        stn = \"{0:05d}\".format(int(st))\n",
    "        ret_dict[stn] = {}\n",
    "        for mon in monthlist:\n",
    "            ret_dict[stn][mon] = {}\n",
    "            for var in varlist:\n",
    "                ret_dict[stn][mon][var] = {}\n",
    "                if var in physical_limits:\n",
    "                    ret_dict[stn][mon][var][var+'_max'] = physical_limits[var][1]\n",
    "                    ret_dict[stn][mon][var][var+'_min'] = physical_limits[var][0]\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 228 ms, sys: 16.6 ms, total: 244 ms\n",
      "Wall time: 244 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## limit_dict -- dictionary with stations and limitations\n",
    "\n",
    "## cols = [i for i in fin.columns if not i in ['time','elevation','lon','lat','station','station_name','report_modifier','station_name','station_type','synop_code']]\n",
    "monthlist=list([month,])\n",
    "limit_dict = make_limit_dictionary(stations, physical_limits, monthlist, physical_limits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_criteria(station, month, variable, st_table, limit_dict):\n",
    "    def get_vbounds():\n",
    "        if variable == 'temperature':\n",
    "            maxmindiff = 3 * (st_table[station][variable][variable + '_quantiles'][4] - st_table[station][variable][variable + '_quantiles'][0])\n",
    "            vmax = maxmindiff + st_table[station][variable][variable + '_quantiles'][4]\n",
    "            vmin = -maxmindiff + st_table[station][variable][variable + '_quantiles'][0]\n",
    "        elif variable in ['station_pressure', 'pressure']:\n",
    "            vmax = st_table[station][variable][variable + '_quantiles'][4] * 1.05\n",
    "            vmin = st_table[station][variable][variable + '_quantiles'][0] / 1.05        \n",
    "        else:\n",
    "            vmax = st_table[station][variable][variable + '_quantiles'][4] * 1.5\n",
    "            vmin = st_table[station][variable][variable + '_quantiles'][0] / 1.5\n",
    "        return vmax, vmin   \n",
    "    assert type(station) == str\n",
    "    assert type(variable) == str\n",
    "    assert type(st_table) == dict\n",
    "    \n",
    "    if not variable in st_table[station]:\n",
    "        #print(\"no variable, returning\", variable)\n",
    "        return\n",
    "    \n",
    "    ## if data is too sparse, better leave it\n",
    "    if not variable + '_count' in st_table[station][variable]:\n",
    "        return\n",
    "    \n",
    "    if st_table[station][variable][variable + '_count'] < 2000:\n",
    "        return\n",
    "    \n",
    "    if variable + '_max' in st_table[station][variable]:\n",
    "        #print(\"var found\", variable)\n",
    "        #vmax = st_table[station][variable][variable + '_quantiles'][4] * 1.5\n",
    "        #vmin = st_table[station][variable][variable + '_quantiles'][0] / 1.5\n",
    "        vmax, vmin = get_vbounds()\n",
    "        if not variable + '_max' in limit_dict[station][month][variable]:\n",
    "            limit_dict[station][month][variable][variable + '_max'] = vmax\n",
    "            limit_dict[station][month][variable][variable + '_min'] = vmin\n",
    "        else:\n",
    "            if limit_dict[station][month][variable][variable + '_max'] > vmax:\n",
    "                limit_dict[station][month][variable][variable + '_max'] = vmax\n",
    "            if limit_dict[station][month][variable][variable + '_min'] < vmin:\n",
    "                limit_dict[station][month][variable][variable + '_min'] = vmin\n",
    "    else:\n",
    "        pass\n",
    "        ##print(\"var not found in\",st_table[station][variable], variable)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine statistics and hard limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 303 ms, sys: 2.47 ms, total: 305 ms\n",
      "Wall time: 305 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for strange in range(len(stations)):\n",
    "    for i in limit_dict[\"{0:05d}\".format(stations[strange])][month].keys():\n",
    "        add_criteria(\"{0:05d}\".format(stations[strange]),month,i,st_table, limit_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(limit_dict, open('limit_dict_{0}.pickle'.format(month),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods to plot the problematic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var = 'station_pressure'\n",
    "def find_stlistike():\n",
    "    stlistike = []\n",
    "    f = FloatProgress(min=0, max=len(stations))\n",
    "    display(f)\n",
    "    var = 'pressure'\n",
    "    for st in range(len(stations)):\n",
    "        if np.any(fin[fin['station']==stations[st]][var] > limit_dict[\"{0:05d}\".format(stations[st])][month][var][var + '_max']):\n",
    "            print(st,)\n",
    "            stlistike.append(st)\n",
    "        f.value += 1\n",
    "    return stlistike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_suspicious(var, stlistike):\n",
    "    for st in stlistike:\n",
    "        trtr = fin[fin['station']==stations[st]][['time',var,'station']].drop_duplicates().sort_values('time')    \n",
    "        trtr['datetime'] = (trtr['time']*1.e9).apply(pd.to_datetime)\n",
    "        fig=plt.figure(figsize=(15,10))\n",
    "        plt.plot(trtr['datetime'],trtr[var],'*')\n",
    "        plt.plot(trtr['datetime'],np.ones(len(trtr))*limit_dict[\"{0:05d}\".format(stations[st])][month][var][var + '_max'])\n",
    "        plt.plot(trtr['datetime'],np.ones(len(trtr))*limit_dict[\"{0:05d}\".format(stations[st])][month][var][var + '_min'])\n",
    "        plt.title(\"{0}   {1}\".format(st, len(trtr.index)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_suspicious(var, st):\n",
    "    st = 410\n",
    "    fig=plt.figure(figsize=(15,10))\n",
    "    trtr = fin[fin['station']==stations[st]][['time',var,'station']].drop_duplicates().sort_values('time')\n",
    "    trtr['datetime'] = (trtr['time']*1.e9).apply(pd.to_datetime)\n",
    "    trfilt=trtr[trtr['datetime'].apply(lambda x: x.year) == 2010]\n",
    "    print(len(trfilt))\n",
    "    plt.plot(trfilt['datetime'],trfilt['temperature'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl = find_stlistike()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_suspicious('pressure',stl[160:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all .pickle files in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [pickle.load(open(i,'rb')) for i in glob.glob('limit_dict_*.pickle')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = {}\n",
    "for oo in range(1,13):\n",
    "    a = pickle.load(open('limit_dict_{0}.pickle'.format(oo),'rb'))\n",
    "    for k,v in a.items(): # k is station ID\n",
    "        if not k in fd.keys():\n",
    "            fd[k] = v\n",
    "        else:\n",
    "            fd[k].update(v)\n",
    "pickle.dump(fd, open('limit_dict_year.pickle'.format(month),'wb'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': {'temperature_max': 65, 'temperature_min': -80},\n",
       " 'wind_speed': {'wind_speed_max': 90, 'wind_speed_min': 0},\n",
       " 'pressure': {'pressure_max': 1100, 'pressure_min': 800},\n",
       " 'station_pressure': {'station_pressure_max': 1100,\n",
       "  'station_pressure_min': 400},\n",
       " 'precipitation_1_hour_accumulation': {'precipitation_1_hour_accumulation_max': 200,\n",
       "  'precipitation_1_hour_accumulation_min': 0},\n",
       " 'precipitation_2_hour_accumulation': {'precipitation_2_hour_accumulation_max': 250,\n",
       "  'precipitation_2_hour_accumulation_min': 0},\n",
       " 'precipitation_3_hour_accumulation': {'precipitation_3_hour_accumulation_max': 400,\n",
       "  'precipitation_3_hour_accumulation_min': 0},\n",
       " 'precipitation_6_hour_accumulation': {'precipitation_6_hour_accumulation_max': 400,\n",
       "  'precipitation_6_hour_accumulation_min': 0},\n",
       " 'precipitation_9_hour_accumulation': {'precipitation_9_hour_accumulation_max': 400,\n",
       "  'precipitation_9_hour_accumulation_min': 0},\n",
       " 'precipitation_12_hour_accumulation': {'precipitation_12_hour_accumulation_max': 400,\n",
       "  'precipitation_12_hour_accumulation_min': 0},\n",
       " 'precipitation_15_hour_accumulation': {'precipitation_15_hour_accumulation_max': 400,\n",
       "  'precipitation_15_hour_accumulation_min': 0},\n",
       " 'precipitation_18_hour_accumulation': {'precipitation_18_hour_accumulation_max': 400,\n",
       "  'precipitation_18_hour_accumulation_min': 0},\n",
       " 'precipitation_24_hour_accumulation': {'precipitation_24_hour_accumulation_max': 400,\n",
       "  'precipitation_24_hour_accumulation_min': 0},\n",
       " 'rel_humidity1': {'rel_humidity1_max': 105, 'rel_humidity1_min': 0},\n",
       " 'rel_humidity2': {'rel_humidity2_max': 105, 'rel_humidity2_min': 0},\n",
       " 'rel_humidity3': {'rel_humidity3_max': 105, 'rel_humidity3_min': 0},\n",
       " 'rel_humidity4': {'rel_humidity4_max': 105, 'rel_humidity4_min': 0}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd['01001'][12]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
